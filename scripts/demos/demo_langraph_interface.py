#!/usr/bin/env python3
"""
Demo script for LangGraph-compatible invoke() interface on BaseAgent.

This script demonstrates the new invoke() method that provides LangGraph
node compatibility while maintaining all existing agent functionality.
"""

import asyncio
import sys
from pathlib import Path

# Set up the Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from cognivault.context import AgentContext
from cognivault.agents.refiner.agent import RefinerAgent
from cognivault.llm.factory import LLMFactory
from cognivault.llm.provider_enum import LLMProvider


async def demo_langraph_interface():
    """Demonstrate the LangGraph-compatible invoke() interface."""
    print("ğŸ”— CogniVault LangGraph Interface Demo")
    print("=" * 50)

    # Create a real agent with stub LLM for demo
    llm = LLMFactory.create(LLMProvider.STUB)
    refiner = RefinerAgent(llm=llm)

    # Create context
    context = AgentContext(query="What are the benefits of renewable energy?")

    print("\n1. ğŸš€ Standard invoke() method (LangGraph compatible)")
    print("-" * 30)

    # Test basic invoke without config
    result1 = await refiner.invoke(context)

    print(f"âœ… Agent executed successfully via invoke()")
    print(f"ğŸ“Š Execution count: {refiner.execution_count}")
    print(f"ğŸ“Š Success count: {refiner.success_count}")
    print(
        f"ğŸ“ Output preview: {result1.agent_outputs.get('RefinerAgent', 'No output')[:100]}..."
    )

    print("\n2. âš™ï¸ invoke() with configuration parameters")
    print("-" * 30)

    # Reset context for clean demo
    context2 = AgentContext(query="How does machine learning work?")

    # Test invoke with configuration
    config = {
        "step_id": "demo_langraph_step_001",
        "timeout_seconds": 45.0,  # Override default timeout
    }

    result2 = await refiner.invoke(context2, config=config)

    print(f"âœ… Agent executed with custom config")
    print(f"ğŸ”§ Custom step_id used: demo_langraph_step_001")
    print(f"â±ï¸ Timeout override applied and restored")
    print(f"ğŸ“Š Total executions: {refiner.execution_count}")

    # Verify step metadata
    metadata_key = f"{refiner.name}_step_metadata"
    if metadata_key in context2.execution_state:
        metadata = context2.execution_state[metadata_key]
        print(f"ğŸ“‹ Step metadata captured: {metadata['step_id']}")

    print("\n3. ğŸ”„ Comparison with traditional run_with_retry()")
    print("-" * 30)

    # Show that both methods work the same way
    context3 = AgentContext(query="Explain quantum computing")

    # Traditional method
    result3 = await refiner.run_with_retry(context3)

    print(f"âœ… Traditional run_with_retry() also works")
    print(f"ğŸ“Š Total executions now: {refiner.execution_count}")
    print(f"ğŸ”— Both interfaces use the same underlying logic")

    print("\n4. ğŸ“ˆ Agent Statistics")
    print("-" * 30)

    stats = refiner.get_execution_stats()
    print(f"Agent Name: {stats['agent_name']}")
    print(f"Total Executions: {stats['execution_count']}")
    print(f"Success Rate: {stats['success_rate']:.2%}")
    print(f"Retry Config: max_retries={stats['retry_config']['max_retries']}")

    print("\n5. ğŸ“‹ LangGraph Node Metadata")
    print("-" * 30)

    # Get node definition
    node_def = refiner.get_node_definition()

    print(f"ğŸ“Š Node ID: {node_def.node_id}")
    print(f"ğŸ·ï¸ Node Type: {node_def.node_type.value}")
    print(f"ğŸ“ Description: {node_def.description}")
    print(f"ğŸ”— Dependencies: {node_def.dependencies}")
    print(f"ğŸ·ï¸ Tags: {node_def.tags}")

    # Show input/output schemas
    print(f"\nğŸ“¥ Inputs ({len(node_def.inputs)}):")
    for inp in node_def.inputs:
        required_str = "required" if inp.required else "optional"
        print(f"   â€¢ {inp.name} ({inp.type_hint}) - {required_str}")
        print(f"     {inp.description}")

    print(f"\nğŸ“¤ Outputs ({len(node_def.outputs)}):")
    for out in node_def.outputs:
        print(f"   â€¢ {out.name} ({out.type_hint})")
        print(f"     {out.description}")

    print("\n6. ğŸ”§ Node Definition as Dictionary")
    print("-" * 30)

    # Convert to dictionary for graph construction
    node_dict = node_def.to_dict()
    import json

    print("Dictionary representation (for graph builders):")
    print(json.dumps(node_dict, indent=2)[:400] + "...")

    print("\n7. âœ… Node Validation")
    print("-" * 30)

    # Test node compatibility validation
    test_context = AgentContext(query="Test validation")
    is_compatible = refiner.validate_node_compatibility(test_context)
    print(f"Context compatibility: {'âœ… Valid' if is_compatible else 'âŒ Invalid'}")

    print("\nâœ¨ LangGraph Node Features:")
    print("   â€¢ invoke(state, config) method signature")
    print("   â€¢ Node metadata with input/output schemas")
    print("   â€¢ Node type classification (processor, decision, terminator, aggregator)")
    print("   â€¢ Dependency declaration")
    print("   â€¢ Configuration parameter support")
    print("   â€¢ Input validation")
    print("   â€¢ Dictionary serialization for graph builders")
    print("   â€¢ All existing retry/circuit breaker functionality preserved")

    print("\nğŸ¯ Ready for LangGraph DAG Integration!")


if __name__ == "__main__":
    asyncio.run(demo_langraph_interface())
