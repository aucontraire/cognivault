# ğŸ§  CogniVault

![Python](https://img.shields.io/badge/python-3.12-blue)
![Coverage](https://img.shields.io/badge/coverage-100%25-brightgreen)
![License](https://img.shields.io/badge/license-AGPL--3.0-blue)
![Markdown Export](https://img.shields.io/badge/markdown-export-green)
![Wiki Ready](https://img.shields.io/badge/wiki-ready-blueviolet)

CogniVault is a modular, CLI-based multi-agent assistant designed to help you reflect, refine, and organize your thoughts through structured dialogue and cumulative insight. It simulates a memory-augmented thinking partner, enabling long-term knowledge building across multiple agent perspectives.

---

## âš¡ Quickstart

Clone the repo and run a basic question through the CLI:

```bash
git clone https://github.com/aucontraire/cognivault.git
cd cognivault
bash setup.sh
make run QUESTION="What are the long-term effects of AI in education?"
```

See [ğŸ–¥ï¸ Usage](#ï¸usage) for running specific agents and debugging options.

---

## ğŸš€ Features

- âœ… **Fully working CLI** using [Typer](https://typer.tiangolo.com/)
- ğŸ§  **Multi-agent orchestration**: Refiner, Historian, Critic, Synthesis
- ğŸ” **Orchestrator pipeline** supports dynamic agent control
- ğŸ“„ **Markdown-ready output** for integration with personal wikis
- ğŸ§ª **Full test suite** with `pytest` for all core components
- ğŸ”„ **Swappable LLM backend**: Plug-and-play support for OpenAI or stubs via configuration

---

## ğŸ§± Project Structure

```
src/
â”œâ”€â”€ cognivault/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ critic/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ historian/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ refiner/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â””â”€â”€ synthesis/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ agent.py
â”‚   â”‚       â””â”€â”€ main.py
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â”œâ”€â”€ context.py
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ LANDSCAPE.md
â”‚   â”‚   â””â”€â”€ RESEARCH.md
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_interface.py
â”‚   â”‚   â”œâ”€â”€ openai.py
â”‚   â”‚   â””â”€â”€ stub.py
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â””â”€â”€ interaction_00001.json
â”‚   â”œâ”€â”€ notes/
â”‚   â”‚   â”œâ”€â”€ 2025-06-26T06-45-24_what-is-cognition.md
â”‚   â”‚   â”œâ”€â”€ 2025-06-26T06-47-28_what-is-cognition.md
â”‚   â”‚   â”œâ”€â”€ 2025-06-26T10-04-47_what-is-cognition.md
â”‚   â”‚   â””â”€â”€ sample_note.md
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â””â”€â”€ store/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ utils.py
â”‚       â””â”€â”€ wiki_adapter.py
tests/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ critic/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”‚   â””â”€â”€ test_main.py
â”‚   â”œâ”€â”€ historian/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”‚   â””â”€â”€ test_main.py
â”‚   â”œâ”€â”€ refiner/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”‚   â””â”€â”€ test_main.py
â”‚   â””â”€â”€ synthesis/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_agent.py
â”‚       â””â”€â”€ test_main.py
â”œâ”€â”€ test_base_agent.py
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_llm_interface.py
â”‚   â”œâ”€â”€ test_openai.py
â”‚   â””â”€â”€ test_stub.py
â”œâ”€â”€ store/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_utils.py
â”‚   â””â”€â”€ test_wiki_adapter.py
â”œâ”€â”€ test_cli.py
â”œâ”€â”€ test_context.py
â””â”€â”€ test_orchestrator.py
```

---

## ğŸ§  Agent Roles

Each agent in CogniVault plays a distinct role in the cognitive reflection and synthesis pipeline:

- ### ğŸ” Refiner
  The **RefinerAgent** takes the initial user input and clarifies intent, rephrases vague language, and ensures the prompt is structured for deeper analysis by the rest of the system.  
  ğŸ“„ [RefinerAgent Charter](./docs/agents/refiner/charter.md)

- ### ğŸ§¾ Historian
  The **HistorianAgent** provides relevant context from previous conversations or memory. It simulates long-term knowledge by surfacing pertinent background or earlier reflections.

- ### ğŸ§  Critic
  The **CriticAgent** evaluates the refined input or historical perspective. It identifies assumptions, weaknesses, or inconsistenciesâ€”acting as a thoughtful devilâ€™s advocate.

- ### ğŸ§µ Synthesis
  The **SynthesisAgent** gathers the outputs of the other agents and composes a final, unified response. This synthesis is designed to be insightful, coherent, and markdown-friendly for knowledge wikis or future reflection.

---

## ğŸ› ï¸ Installation & Setup

To get started quickly:

```bash
bash setup.sh
```

This script will:

- Create a Python 3.12.2 virtual environment using `pyenv`
- Install dependencies from `requirements.txt`
- Install Git hooks to enforce formatting, type-checking, and testing before commits and pushes

If you don't have `pyenv` installed, refer to: https://github.com/pyenv/pyenv#installation

### Git Hooks (Optional Manual Setup)

Hooks are installed automatically by `setup.sh`, but you can manually install or review them:

- `pre-commit`: Runs code formatter (`make format`) and type checks (`make typecheck`)
- `pre-push`: Runs test suite (`make test`)

---

## ğŸ” LLM Configuration

CogniVault supports OpenAI out of the box via a `.env` file in the root of the project:

```env
OPENAI_API_KEY=your-key-here
OPENAI_MODEL=gpt-4
OPENAI_API_BASE=https://api.openai.com/v1  # Optional
```

These credentials are automatically loaded using `python-dotenv` via the `OpenAIConfig` class in `cognivault/config/openai_config.py`.

You can define new LLMs or stubs and inject them by extending the `LLMInterface` contract.

---

## ğŸ–¥ï¸ Usage

### Run the assistant

Make sure your `.env` file is configured with your OpenAI credentials if using the OpenAI LLM backend.

To run the full pipeline with all agents:

```bash
make run QUESTION="Is democracy becoming more robust globally?"
```

This executes:

```bash
PYTHONPATH=src python -m cognivault.cli "$(QUESTION)" $(if $(AGENTS),--agents=$(AGENTS),) $(if $(LOG_LEVEL),--log-level=$(LOG_LEVEL),) $(if $(EXPORT_MD),--export-md,)
```

âš ï¸ Note: `$(QUESTION)` is a Makefile variable â€” this syntax only works with `make run`. If you're calling the Python CLI directly, use standard shell quotes:

```bash
PYTHONPATH=src python -m cognivault.cli "What is cognition?" --agents=refiner,critic
```

You can also run a **single agent in isolation** using the `AGENTS` environment variable:

```bash
make run QUESTION="What are the benefits of a polycentric governance model?" AGENTS=refiner
make run QUESTION="How does historical context affect AI safety debates?" AGENTS=critic
make run QUESTION="What long-term trends influence democratic erosion?" AGENTS=historian
make run QUESTION="Whatâ€™s the synthesized conclusion from all agents?" AGENTS=synthesis
```

This maps to the CLI flag `--agents=name1,name2`, allowing you to run any combination of agents by name. Leave unset to run the full pipeline.

### Control Log Level

You can control the logging verbosity using the `LOG_LEVEL` environment variable. Available levels include `DEBUG`, `INFO`, `WARNING`, and `ERROR`.

```bash
make run QUESTION="your query here" AGENTS=refiner,critic LOG_LEVEL=DEBUG
```

This helps in debugging and understanding agent behavior during development.

### Export Markdown Output

To save the output of agent responses as a markdown file (for integration into a personal wiki or digital garden), use the `EXPORT_MD=1` flag:

```bash
make run QUESTION="What is cognition?" AGENTS=refiner,critic EXPORT_MD=1
```

This will generate a `.md` file in `src/cognivault/notes/` with YAML frontmatter metadata including the title, date, agents, filename, source, and a UUID. The content is formatted for easy future retrieval and indexing.

ğŸ“„ Output saved to: `src/cognivault/notes/2025-06-26T10-04-47_what-is-cognition.md`

With frontmatter like:

```markdown
---
agents:
  - Refiner
  - Critic
date: 2025-06-26T10:04:47
filename: 2025-06-26T10-04-47_what-is-cognition.md
source: cli
summary: Draft response from agents about the definition and scope of the question.
title: What is cognition?
uuid: 8fab709a-8fc4-464a-b16b-b7a55c84aedf
---
```

---

## ğŸ§  Example Output

```markdown
### ğŸ” Refiner:
Clarifies that the user is asking about structural versus cultural forces in education systems.

### ğŸ§¾ Historian:
Recalls that prior conversations touched on ed-tech, teacher labor markets, and digital equity.

### ğŸ§  Critic:
Questions the assumption that AI improves access without reinforcing inequality.

### ğŸ§µ Synthesis:
AIâ€™s long-term effects on education depend on how we resolve tensions between scale and personalization.
```

---

## ğŸ§ª Run Tests

```bash
make test
```

Covers:
- Agent context
- Orchestrator pipeline
- All 4 core agents

### View Coverage

Run the full test suite with a coverage report:

```bash
make coverage-all
```

### Control Log Level During Coverage

You can set a log level when running test coverage to see debug output during test runs:

```bash
LOG_LEVEL=DEBUG make coverage-all
```

This can help trace detailed agent behavior while viewing test coverage results.

This executes:

```bash
PYTHONPATH=src pytest --cov=cognivault --cov-report=term-missing tests/
```

Run coverage on a specific module:

```bash
make coverage-one m=cli LOG_LEVEL=INFO
```

- `m` is required â€” it's the submodule path under `cognivault`.
- `LOG_LEVEL` is optional (defaults to `WARNING`). Set it to `INFO` or `DEBUG` to see logging output during test runs.

ğŸ’¡ Example:
```bash
make coverage-one m=orchestrator LOG_LEVEL=DEBUG
```

---

## ğŸ’¡ Use Cases

CogniVault can serve as a:

- ğŸ§  Personal knowledge management tool (Zettelkasten, digital garden)
- ğŸ’¬ Reflection assistant for journaling or ideation
- ğŸ“š Research co-pilot for synthesis and argument mapping
- ğŸ§µ Semantic trace explorer for AI explainability
- ğŸ§ª Experimentation harness for multi-agent reasoning

Future directions: wiki export, browser UI, plugin support (Obsidian, Notion).

---

## ğŸŒ How CogniVault Differs

Unlike typical LLM assistants or AutoGPT-style agents, CogniVault focuses on *structured introspection* rather than task completion. While tools like LangGraph or Reflexion optimize for task-solving or dynamic planning, CogniVault enables long-term insight formation across modular agent roles â€” including Refiner, Historian, Critic, and Synthesis.

Itâ€™s designed as a memory-enhanced thinking partner that integrates cleanly with personal wikis, supports test-driven CLI use, and remains light enough for future microservice deployment or API integration.

---

## ğŸ”­ Roadmap

- [x] Agent toggles via CLI (`--agents=name1,name2`)
- [x] Asynchronous agent execution
- [ ] Markdown exporter for wiki integration
- [ ] Optional file/vector store persistence
- [ ] API or microservice agent wrappers (e.g. FastAPI)
- [ ] Streamlit UI or Jupyter notebook support

---

## ğŸ›  Built With

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Typer](https://img.shields.io/badge/CLI-Typer-green)
![Pytest](https://img.shields.io/badge/Testing-Pytest-blueviolet)
![AGPL](https://img.shields.io/badge/License-AGPL_3.0-orange)

---

## ğŸ¤ Contributing

Coming soon: contributor guide and code of conduct.

---

## ğŸ“œ License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.  
See the [LICENSE](./LICENSE) file for full terms.